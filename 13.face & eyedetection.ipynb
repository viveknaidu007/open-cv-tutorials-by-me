{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can download haarcascades files from this link\n",
    "#https://github.com/opencv/opencv/tree/4.x/data/haarcascades\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade files\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\poppo\\AppData\\Local\\Temp\\ipykernel_25760\\867849178.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('photos\\group 2.jpg')\n",
    "cv2.imshow('original image' , image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#converting image to grey scale\n",
    "gray = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#deetcting faces\n",
    "faces = face_classifier.detectMultiScale(gray , 1.3 ,5)  #1.3 is scale factor , and 5 is neighbour nnumber\n",
    "\n",
    "if faces is ():\n",
    "    print('no faces found')\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image , (x,y) , (x+w, y+h) , (0,255,128) , 2)  # x,y is starting coordinate and x+w,y+h is ending coordinate  and 2 is like tickness \n",
    "    cv2.imshow('face detection' , image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#eye detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m eye_classifier \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade files\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhaarcascade_eye.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphotos\u001b[39m\u001b[38;5;130;01m\\v\u001b[39;00m\u001b[38;5;124mivek2.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#converting image to grey scale\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade files\\haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade files\\haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "image = cv2.imread('photos\\vivek2.jpeg')\n",
    "cv2.imshow('original image' , image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#converting image to grey scale\n",
    "gray = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#deetcting faces\n",
    "faces = face_classifier.detectMultiScale(gray , 1.3 ,5)  #1.3 is scale factor , and 5 is neighbour nnumber\n",
    "\n",
    "if faces is ():\n",
    "    print('no faces found')\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image , (x,y) , (x+w , y+h) , (255,0,255) , 2)\n",
    "    cv2.imshow('face detection' , image)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h , x:x+w]\n",
    "    roi_color = image[y:y+h , x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color , (ex,ey) , (ex+ew , ex+eh) , (255,45,198) , 2)\n",
    "        cv2.imshow('face detection' , image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
